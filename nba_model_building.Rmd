---
title: "nba_model_builds"
output: html_document
date: "2024-06-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Model Building
```{r}
set.seed(222)
load("/Users/keya0/projects/nbasalary/models/nba_model_setup.rda")
```

## Fitting Models
1.
```{r}
# LINEAR REGRESSION 
lm_model <- linear_reg() %>% 
  set_engine("lm")

# K NEAREST NEIGHBORS
knn_model <- nearest_neighbor(neighbors = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("kknn")

# RIDGE REGRESSION
ridge_spec <- linear_reg(mixture = 0, 
                         penalty = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

# LASSO REGRESSION
lasso_spec <- linear_reg(penalty = tune(), 
                         mixture = 1) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

# POLYNOMIAL REGRESSION
# adding tuning parameter in recipe
poly_recipe <- nba_recipe %>% 
  step_poly(age, gp, gs, mp, x3p_2, x2p_2, e_fg, ft_2, orb, drb, ast, stl, blk, tov, pf, pts, degree = tune())

poly_spec <- linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("lm")

# ELASTIC NET
en_spec <- linear_reg(penalty = tune(), 
                           mixture = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("glmnet")

# RANDOM FOREST
rf_spec <- rand_forest(mtry = tune(), 
                       trees = tune(), 
                       min_n = tune()) %>% 
  set_mode("regression") %>% 
  set_engine("ranger", importance = "impurity")

# BOOSTED TREES
boosted_spec <- boost_tree(mtry = tune(),
                           trees = tune(),
                           learn_rate = tune()) %>%
  set_mode("regression") %>%
  set_engine("xgboost")
```
2.
```{r}
# LINEAR REGRESSION 
lm_workflow <- workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(nba_recipe)

# K NEAREST NEIGHBORS
knn_workflow <- workflow() %>% 
  add_model(knn_model) %>% 
  add_recipe(nba_recipe)

# RIDGE REGRESSION
ridge_workflow <- workflow() %>% 
  add_recipe(nba_recipe) %>% 
  add_model(ridge_spec)

# LASSO REGRESSION
lasso_workflow <- workflow() %>% 
  add_recipe(nba_recipe) %>% 
  add_model(lasso_spec)

# POLYNOMIAL REGRESSION
poly_wf <- workflow() %>% 
  add_model(poly_spec) %>% 
  add_recipe(poly_recipe)

# ELASTIC NET
en_workflow <- workflow() %>% 
  add_recipe(nba_recipe) %>% 
  add_model(en_spec)

# RANDOM FOREST
rf_workflow <- workflow() %>% 
  add_recipe(nba_recipe) %>% 
  add_model(rf_spec)

# BOOSTED TREES
boosted_workflow <- workflow() %>% 
  add_recipe(nba_recipe) %>% 
  add_model(boosted_spec)
```

3.
```{r}
# K NEAREST NEIGHBORS
knn_grid <- grid_regular(neighbors(range = c(1,15)), 
                         levels = 5)

# RIDGE REGRESSION
penalty_grid <- grid_regular(penalty(range = c(1, 6)), 
                             levels = 50)

# LASSO REGRESSION
# same as ridge

# POLYNOMIAL REGRESSION
degree_grid <- grid_regular(degree(range = c(1,10)), 
                            levels = 10)

# ELASTIC NET
en_grid <- grid_regular(penalty(range = c(1, 10)), 
                        mixture(range = c(0,1)), 
                        levels = 10)

# RANDOM FOREST
rf_grid <- grid_regular(mtry(range = c(1, 21)),
                        trees(range = c(200, 800)),
                        min_n(range = c(5, 20)), 
                        levels = 6)

# BOOSTED TREES
boosted_grid <- grid_regular(mtry(range = c(1, 21)),
                             trees(range = c(200, 800)), 
                             learn_rate(range = c(-5, -1)),
                             levels = 6)
```

4.
```{r}
# K NEAREST NEIGHBORS
knn_tuned <- tune_grid(
  knn_workflow,
  resamples = nba_folds,
  grid = knn_grid)

# RIDGE REGRESSION
ridge_tuned <- tune_grid(
  ridge_workflow,
  resamples = nba_folds,
  grid = penalty_grid)

# LASSO REGRESSION
lasso_tuned <- tune_grid(
  lasso_workflow,
  resamples = nba_folds,
  grid = penalty_grid)

# POLYNOMIAL REGRESSION
poly_tuned <- tune_grid(
  poly_wf,
  resamples = nba_folds,
  grid = degree_grid,
  metrics = metric_set(yardstick::rmse))

# ELASTIC NET
en_tuned <- tune_grid(
  en_workflow,
  resamples = nba_folds,
  grid = en_grid)

# RANDOM FOREST
rf_tuned <- tune_grid(
  rf_workflow,
  resamples = nba_folds,
  grid = rf_grid)

# BOOSTED TREES
boosted_tuned <- tune_grid(
  boosted_workflow,
  resamples = nba_folds,
  grid = boosted_grid)
```

5.
```{r}
lm_fit <- fit_resamples(lm_workflow, resamples = nba_folds)

lm_rmse <- lm_fit %>% 
  collect_metrics() %>%
  filter(.metric == "rmse") %>%
  pull(mean)

knn_best <- select_best(knn_tuned, metric = 'rmse')
knn_rmse <- knn_tuned %>% 
  collect_metrics() %>% 
  filter(.config == knn_best$.config, .metric == "rmse") %>% 
  pull(mean)

ridge_best <- select_best(ridge_tuned, metric = 'rmse')
ridge_rmse <- ridge_tuned %>% 
  collect_metrics() %>% 
  filter(.config == ridge_best$.config, .metric == "rmse") %>% 
  pull(mean)

lasso_best <- select_best(lasso_tuned, metric = 'rmse')
lasso_rmse <- lasso_tuned %>% 
  collect_metrics() %>% 
  filter(.config == lasso_best$.config, .metric == "rmse") %>% 
  pull(mean)

poly_best <- select_best(poly_tuned, metric = 'rmse')
poly_rmse <- poly_tuned %>% 
  collect_metrics() %>% 
  filter(.config == poly_best$.config, .metric == "rmse") %>% 
  pull(mean)

en_best <- select_best(en_tuned, metric = 'rmse')
en_rmse <- en_tuned %>% 
  collect_metrics() %>% 
  filter(.config == en_best$.config, .metric == "rmse") %>% 
  pull(mean)

rf_best <- select_best(rf_tuned, metric = 'rmse')
rf_rmse <- rf_tuned %>% 
  collect_metrics() %>% 
  filter(.config == rf_best$.config, .metric == "rmse") %>% 
  pull(mean)

boosted_best <- select_best(boosted_tuned, metric = 'rmse')
boosted_rmse <- boosted_tuned %>% 
  collect_metrics() %>% 
  filter(.config == boosted_best$.config, .metric == "rmse") %>% 
  pull(mean)
```


```{r}
# LINEAR REGRESSION
save(lm_fit, lm_rmse, file = "/Users/keya0/projects/nbasalary/models/lm.rda")

# K NEAREST NEIGHBORS
save(knn_tuned, knn_best, knn_rmse, file = "/Users/keya0/projects/nbasalary/models/knn.rda")

# RIDGE REGRESSION
save(ridge_tuned, ridge_best, ridge_rmse, file = "/Users/keya0/projects/nbasalary/models/ridge.rda")

# LASSO REGRESSION
save(lasso_tuned, lasso_best, lasso_rmse, file = "/Users/keya0/projects/nbasalary/models/lasso.rda")

# POLYNOMIAL REGRESSION
save(poly_tuned, poly_best, poly_rmse, file = "/Users/keya0/projects/nbasalary/models/poly.rda")

# ELASTIC NET
save(en_tuned, en_best, en_rmse, file = "/Users/keya0/projects/nbasalary/models/en.rda")

# RANDOM FOREST
save(rf_tuned, rf_best, rf_rmse, file = "/Users/keya0/projects/nbasalary/models/rf.rda")

# BOOSTED TREES
save(boosted_tuned, boosted_best, boosted_rmse, file = "/Users/keya0/projects/nbasalary/models/boosted.rda")
```
